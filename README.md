# ğŸš¨ SightGuardian: AI-Powered Smart Surveillance System

![Banner](./assets/sightguardian-banner.png)
*Detect. Analyze. Protect. â€” Real-time smart surveillance made practical with Hugging Face models.*

---

## ğŸ“Œ Overview

**SightGuardian** is an AI-driven surveillance assistant designed to detect and report suspicious behavior, safety hazards, or emergency events from real-time video streams.

This project uses cutting-edge models from [Hugging Face](https://huggingface.co/) to intelligently process video feeds, identify abnormal activities (e.g., fights, fire, weapons), and deliver actionable alerts â€” all while preserving privacy and enabling scalability.

---

## ğŸ’¡ Key Features

* ğŸ¯ Real-time **object detection** (e.g., people, weapons, smoke)
* ğŸ§  **Anomaly detection** for violence, loitering, or falls
* ğŸ”¥ Fire & smoke detection using **image classification**
* ğŸ“ Auto-generated **incident reports** using text generation
* ğŸ“ **Location-aware** tracking with map-based dashboards
* âš ï¸ Alerting system with webhooks, email, or SMS
* ğŸ›¡ï¸ Privacy-first: no facial recognition, edge-processing support
* ğŸŒ Scalable architecture (cloud or on-prem)

---

## ğŸ” Use Cases

* City surveillance & smart city initiatives
* Public event crowd monitoring
* Retail and warehouse security
* School & campus safety enforcement

---

## ğŸ§  AI Tasks Used (from Hugging Face)

| Task                        | Purpose                                             |
| --------------------------- | --------------------------------------------------- |
| `Object Detection`          | Identify threats like weapons or suspicious objects |
| `Video Classification`      | Detect violent or unusual behavior                  |
| `Image Segmentation`        | Extract people/objects from background              |
| `Text Generation`           | Summarize detected events                           |
| `Visual Question Answering` | Ask questions like â€œis someone lying down?â€         |
| `Depth Estimation`          | Estimate distance between entities                  |
| `Image-to-Text`             | Describe scenes for auto-reporting                  |

---

## ğŸ§° Tech Stack

### Frontend

* [Next.js](https://nextjs.org/)
* [Tailwind CSS](https://tailwindcss.com/)
* [Mapbox](https://www.mapbox.com/) / Google Maps API
* [Socket.IO](https://socket.io/) for live alert streaming

### Backend

* [FastAPI](https://fastapi.tiangolo.com/)
* [PostgreSQL](https://www.postgresql.org/) + PostGIS
* [Redis](https://redis.io/) for task queuing
* [OpenCV](https://opencv.org/) + [FFmpeg](https://ffmpeg.org/) for video processing

### AI/ML

* [Transformers](https://huggingface.co/transformers/)
* [PyTorch](https://pytorch.org/)
* [ONNX Runtime](https://onnxruntime.ai/)
* [YOLOv7](https://github.com/WongKinYiu/yolov7) or Hugging Face vision models

---

## ğŸ–¼ï¸ System Architecture

```
[Camera Stream or RTSP Feed]
      â†“
[Video Preprocessor (OpenCV/FFmpeg)]
      â†“
[Inference Engine (Object Detection, Anomaly, Segmentation)]
      â†“
[Alert Scorer & Event Aggregator]
      â†“
[PostgreSQL + Redis Queue]
      â†“                   â†“
[Incident Report Engine]  [Alert Notifier]
      â†“                   â†“
[Frontend Dashboard (Map + Timeline + Viewer)]
```

---

## ğŸ“¸ Screenshots (Mockups)

> Replace with real screenshots once implemented

| Live Detection              | Incident Timeline          | Report Example           |
| --------------------------- | -------------------------- | ------------------------ |
| ![](./assets/live-feed.png) | ![](./assets/timeline.png) | ![](./assets/report.png) |

---

## âš™ï¸ Setup Instructions

### 1. Clone the Repo

```bash
git clone https://github.com/yourusername/sightguardian.git
cd sightguardian
```

### 2. Backend Setup

```bash
cd backend
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
uvicorn main:app --reload
```

### 3. Frontend Setup

```bash
cd frontend
npm install
npm run dev
```

### 4. Start Camera Feed (for testing)

```bash
ffmpeg -i test-video.mp4 -f image2pipe -vcodec rawvideo -pix_fmt rgb24 -
```

---

## ğŸ§ª Sample Data Sources

* Public camera feeds: [https://trafficcams.com/](https://trafficcams.com/)
* Drone data: [OpenAerialMap](https://openaerialmap.org/)
* Video datasets: [UCF-Crime](http://crimelab.cs.ucf.edu/), [VIRAT Video](https://viratdata.org/)

---

## ğŸš€ Roadmap

* [x] Object detection (people, weapons, fire)
* [x] Incident report generation
* [ ] Real-time video streaming from edge devices
* [ ] Activity recognition (e.g., falls, fights)
* [ ] VQA module integration
* [ ] Admin dashboard with permissions
* [ ] Docker + Kubernetes deployment support

---

## ğŸ›¡ï¸ Ethical & Privacy Principles

* ğŸš« No facial recognition used
* âœ… Edge inference supported to avoid cloud video uploads
* ğŸ“œ Transparent logging and data retention policies
* ğŸ‘® Human-in-the-loop alerts for critical events

---

## ğŸ“ˆ Performance Goals

| Metric              | Target  |
| ------------------- | ------- |
| Detection Accuracy  | â‰¥ 85%   |
| False Positive Rate | â‰¤ 10%   |
| Report Latency      | â‰¤ 3 sec |
| Stream Delay        | â‰¤ 2 sec |

---

## ğŸ¤ Contributing

1. Fork the repo and clone it locally.
2. Create a new branch: `feat/your-feature-name`.
3. Make your changes and commit: `git commit -m 'feat: added new feature'`
4. Push to the branch: `git push origin feat/your-feature-name`
5. Open a pull request!

---

## ğŸ“„ License

[MIT](LICENSE)

---

## ğŸ’¬ Contact

Built by [Your Name](https://yourwebsite.com)
ğŸ”— LinkedIn Â· ğŸ’¼ Portfolio Â· âœ‰ï¸ [azeemshafeeq125@gmail.com](mailto:azeemshafeeq125@gmail.com)

---

## â­ï¸ Show Your Support

If you like this project, please give it a â­ï¸ and share it with others!

